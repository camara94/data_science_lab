{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76845e28",
   "metadata": {},
   "source": [
    "<font size=\"+3\"><strong>Preparing Mexico Data</strong></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eee83d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "from IPython.display import VimeoVideo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9263ec",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4bda5e",
   "metadata": {},
   "source": [
    "The first part of any data science project is preparing your data, which means making sure its in the right place and format for you to conduct your analysis. The first step of any data preparation is importing your raw data and cleaning it. \n",
    "\n",
    "If you look in the `small-data` directory on your machine, you'll see that the data for this project comes in three CSV files: `mexico-real-estate-1.csv`, `mexico-real-estate-2.csv`, and `mexico-real-estate-3.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "baa73b41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"600\"\n",
       "            height=\"300\"\n",
       "            src=\"https://player.vimeo.com/video/656321516?h=e85e3bf248\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.VimeoVideo at 0x1c33ec52580>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VimeoVideo(\"656321516\", h=\"e85e3bf248\", width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e1a7ca",
   "metadata": {},
   "source": [
    "**Task 1.2.1:** Read these three files into three separate DataFrames named `df1`, `df2`, and `df3`, respectively.\n",
    "\n",
    "- [What's a DataFrame?](../%40textbook/03-pandas-getting-started.ipynb#Pandas)\n",
    "- [What's a CSV file?](../%40textbook/03-pandas-getting-started.ipynb#CSV-Files)\n",
    "- [Read a CSV file into a DataFrame using pandas.](../%40textbook/03-pandas-getting-started.ipynb#Working-with-DataFrames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f62076",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"data/mexico-real-estate-1.csv\")\n",
    "df2 = pd.read_csv(\"data/mexico-real-estate-2.csv\")\n",
    "df3 = pd.read_csv(\"data/mexico-real-estate-3.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a64989f",
   "metadata": {},
   "source": [
    "## Clean `df1`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7b52ee",
   "metadata": {},
   "source": [
    "Now that you have your three DataFrames, it's time to inspect them to see if they need any cleaning. Let's look at them one-by-one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6bee40d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"600\"\n",
       "            height=\"300\"\n",
       "            src=\"https://player.vimeo.com/video/656320563?h=a6841fed28\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.VimeoVideo at 0x1c33ec53d30>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VimeoVideo(\"656320563\", h=\"a6841fed28\", width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b206536",
   "metadata": {},
   "source": [
    "**Task 1.2.2:** Inspect `df1` by looking at its [`shape`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.shape.html) attribute. Then use the [`info`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.info.htm) method to see the data types and number of missing values for each column. Finally, use the [`head`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.head.html) method to determine to look at the first five rows of your dataset.\n",
    "\n",
    "- [Inspect a DataFrame using the `shape`, `info`, and `head` in pandas.](../%40textbook/03-pandas-getting-started.ipynb#Inspecting-DataFrames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbae8aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fcd271",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4171fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce545be7",
   "metadata": {},
   "source": [
    "It looks like there are a couple of problems in this DataFrame that you need to solve. First, there are many rows with `NaN` values in the `\"lat\"` and `\"lon\"` columns. Second, the data type for the `\"price_usd\"` column is `object` when it should be `float`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17a5c98a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"600\"\n",
       "            height=\"300\"\n",
       "            src=\"https://player.vimeo.com/video/656316512?h=33eb5cb26e\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.VimeoVideo at 0x1c33ec625e0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VimeoVideo(\"656316512\", h=\"33eb5cb26e\", width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f297b3",
   "metadata": {},
   "source": [
    "**Task 1.2.3:** Clean `df1` by dropping rows with `NaN` values. Then remove the `\"$\"` and `\",\"` characters from `\"price_usd\"` and recast the values in the column as floats.\n",
    "\n",
    "- [What's a data type?](../%40textbook/01-python-getting-started.ipynb#Data-Types)\n",
    "- [Drop rows with missing values from a DataFrame using pandas.](../%40textbook/03-pandas-getting-started.ipynb#Dropping-Rows)\n",
    "- [Replace string characters in a column using pandas.](../%40textbook/03-pandas-getting-started.ipynb#Replacing-String-Characters) \n",
    "- [Recast a column as a different data type in pandas.](../%40textbook/03-pandas-getting-started.ipynb#Recasting-Data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9608eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ce05e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763b31b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.price_usd = (df1.price_usd.str.replace(\"$\", \"\", regex=True).str.replace(\",\", \"\").astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a79e8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a5cb68",
   "metadata": {},
   "source": [
    "## Clean `df2`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27726ffc",
   "metadata": {},
   "source": [
    "Now it's time to tackle `df2`. Take a moment to inspect it using the same commands you used before. You'll notice that it has the same issue of `NaN` values, but there's a new problem, too: The home prices are in Mexican pesos (`\"price_mxn\"`), not US dollars (`\"price_usd\"`). If we want to compare all the home prices in this dataset, they all need to be in the same currency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96d1a549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"600\"\n",
       "            height=\"300\"\n",
       "            src=\"https://player.vimeo.com/video/656315668?h=c9bd116aca\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.VimeoVideo at 0x1c33db74490>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VimeoVideo(\"656315668\", h=\"c9bd116aca\", width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5376d996",
   "metadata": {},
   "source": [
    "**Task 1.2.4:** First, drop rows with `NaN` values in `df2`. Next, use the `\"price_mxn\"` column to create a new column named `\"price_usd\"`. (Keep in mind that, when this data was collected in 2014, a dollar cost 19 pesos.) Finally, drop the `\"price_mxn\"` from the DataFrame.\n",
    "\n",
    "- [Drop rows with missing values from a DataFrame using pandas.](../%40textbook/03-pandas-getting-started.ipynb#Dropping-Rows)\n",
    "- [Create new columns derived from existing columns in a DataFrame using pandas.](../%40textbook/03-pandas-getting-started.ipynb#Adding-Columns)\n",
    "- [Drop a column from a DataFrame using pandas.](../%40textbook/03-pandas-getting-started.ipynb#Dropping-Columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a065f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cddc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3999ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop `NAN`\n",
    "df2.dropna(inplace=True)\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a8d586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# round `\"price_usd\"`\n",
    "df2.price_usd = df2.price_usd.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7392cf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop `\"price_mxn\"`\n",
    "df2.drop([\"price_mxn\"], axis=1, inplace=True)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791b1851",
   "metadata": {},
   "source": [
    "## Clean `df3`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16003f01",
   "metadata": {},
   "source": [
    "Great work! We're now on the final DataFrame. Use the same `shape`, `info` and `head` commands to inspect the `df3`. Do you see any familiar issues? \n",
    "\n",
    "You'll notice that we still have `NaN` values, but there are two new problems:\n",
    "\n",
    "1. Instead of separate `\"lat\"` and `\"lon\"` columns, there's a single `\"lat-lon\"` column. \n",
    "2. Instead of a `\"state\"` column, there's a `\"place_with_parent_names\"` column.\n",
    "\n",
    "We need the resolve these problems so that `df3` has the same columns in the same format as `df1` and `df2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c745264a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"600\"\n",
       "            height=\"300\"\n",
       "            src=\"https://player.vimeo.com/video/656314718?h=8d1127a93f\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.VimeoVideo at 0x1c33dae4f10>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VimeoVideo(\"656314718\", h=\"8d1127a93f\", width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13dd3a25",
   "metadata": {},
   "source": [
    "**Task 1.2.5:** Drop rows with `NaN` values in `df3`. Then use the [`split`](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.split.html) method to create two new columns from `\"lat-lon\"` named `\"lat\"` and `\"lon\"`, respectively.\n",
    "\n",
    "- [Drop rows with missing values from a DataFrame using pandas.](../%40textbook/03-pandas-getting-started.ipynb#Dropping-Rows)\n",
    "- [Split the strings in one column to create another using pandas.](../%40textbook/03-pandas-getting-started.ipynb#Splitting-Strings) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebfb932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inpect first 5 row \n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aed128e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect col, row, datatype\n",
    "df3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c9b3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split `\"lat-lon\"`\n",
    "df3[[\"lat\", \"lon\"]] = df3[\"lat-lon\"].str.split(\",\", expand=True)\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f66a306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop `\"NaN\"`\n",
    "df3.dropna(inplace=True)\n",
    "df3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6897af9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"600\"\n",
       "            height=\"300\"\n",
       "            src=\"https://player.vimeo.com/video/656314050?h=13f6a677fd\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.VimeoVideo at 0x1c33ec62520>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VimeoVideo(\"656314050\", h=\"13f6a677fd\", width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdac5f9b",
   "metadata": {},
   "source": [
    "**Task 1.2.6:** Use the [`split`](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.split.html) method again, this time to extract the state for every house. (Note that the state name always appears after `\"México|\"` in each string.) Use this information to create a `\"state\"` column. Finally, drop the `\"place_with_parent_names\"` and `\"lat-lon\"` columns from the DataFrame. \n",
    "\n",
    "- [Split the strings in one column to create another using pandas.](../%40textbook/03-pandas-getting-started.ipynb#Splitting-Strings)\n",
    "- [Drop a column from a DataFrame using pandas.](../%40textbook/03-pandas-getting-started.ipynb#Dropping-Columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82331ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create `\"state\"` from `\"place_with_parent_names\"`\n",
    "df3[\"state\"] = df3[\"place_with_parent_names\"].str.split(\"|\", expand=True)[2]\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7c1dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop col `\"place_with_parent_names\"` and `\"lat-lon\"`\n",
    "\n",
    "df3.drop(columns=[\"place_with_parent_names\", \"lat-lon\"], inplace=True)\n",
    "\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29443f57",
   "metadata": {},
   "source": [
    "## Concatenate DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5965bf",
   "metadata": {},
   "source": [
    "Great work! You have three clean DataFrames, and now it's time to combine them into a single DataFrame so that you can conduct your analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82d8e064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"600\"\n",
       "            height=\"300\"\n",
       "            src=\"https://player.vimeo.com/video/656313395?h=ccadbc2689\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.VimeoVideo at 0x1c33ec62f70>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VimeoVideo(\"656313395\", h=\"ccadbc2689\", width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d296b25c",
   "metadata": {},
   "source": [
    "**Task 1.2.7:** Use [`pd.concat`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html) to concatenate `df1`, `df2`, `df3` as new DataFrame named `df`. Your new DataFrame should have 1,736 rows and 6 columns:`\"property_type\"`, `\"state\"`, `\"lat\"`, `\"lon\"`, `\"area_m2\"`, `\"price_usd\"`, and `\"price_per_m2\"`. \n",
    "\n",
    "- [Concatenate two or more DataFrames using pandas.](../%40textbook/03-pandas-getting-started.ipynb#Concatenating-DataFrames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1648dae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1, df2, df3])\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485b76fc",
   "metadata": {},
   "source": [
    "## Save `df`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c340a1d1",
   "metadata": {},
   "source": [
    "The data is clean and in a single DataFrame, and now you need to save it as a CSV file so that you can examine it in your exploratory data analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db336197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"600\"\n",
       "            height=\"300\"\n",
       "            src=\"https://player.vimeo.com/video/656312464?h=81ee04de15\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.VimeoVideo at 0x1c33db79490>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VimeoVideo(\"656312464\", h=\"81ee04de15\", width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79837329",
   "metadata": {},
   "source": [
    "**Task 1.2.8:** Save `df` as a CSV file using the [`to_csv`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html) method. The file path should be `\"./data/mexico-real-estate-clean.csv\"`. Be sure to set the `index` argument to `False`.\n",
    "\n",
    "- [What's a CSV file?](../%40textbook/03-pandas-getting-started.ipynb#CSV-Files)\n",
    "- [Save a DataFrame as a CSV file using pandas.](../%40textbook/03-pandas-getting-started.ipynb#Saving-a-DataFrame-as-a-CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6f33ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./data/mexico-real-estate-clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2754634",
   "metadata": {},
   "source": [
    "# Summary\n",
    "What I will do in this lab\n",
    "1. import package\n",
    "2. read data\n",
    "3. drop data\n",
    "4. fill miss data\n",
    "5. clean data\n",
    "6. reformating data\n",
    "7. combine dataframe\n",
    "8. create new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e83073",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
